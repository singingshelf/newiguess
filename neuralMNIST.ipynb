{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, input_size=718, hidden_layers=[512, 512], output_size=10):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_size = output_size\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Input to Hidden Layers Network\n",
    "        self.weights.append(0.01 * np.random.rand(input_size, hidden_layers[0]))\n",
    "        self.biases.append(np.zeros((1, hidden_layers[0])))\n",
    "\n",
    "        # Hidden Layers Network\n",
    "        for i in range(len(hidden_layers)-1):\n",
    "            self.weights.append(0.01 * np.random.rand(hidden_layers[i], hidden_layers[i+1]))\n",
    "            self.biases.append(np.zeros((1, hidden_layers[i+1])))\n",
    "        \n",
    "        # Hidden Layers Network to Output\n",
    "        self.weights.append(0.01 * np.random.rand(hidden_layers[len(hidden_layers)-1], output_size))\n",
    "        self.biases.append(np.zeros((1, output_size)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        layers = [inputs]\n",
    "        print(layers[-1].shape)\n",
    "\n",
    "        for i in range(len(self.weights)):\n",
    "            # Dot Product to \n",
    "            layers.append(np.dot(layers[-1], self.weights[i]) + self.biases[i])\n",
    "\n",
    "            # Activation Functions (ReLU + SoftMax)\n",
    "            if i == len(self.weights)-1:\n",
    "\n",
    "                finalOutput = np.exp(layers[-1])\n",
    "                sum = np.sum(finalOutput)\n",
    "                finalOutput = finalOutput / sum\n",
    "                layers.append(finalOutput)\n",
    "            else:\n",
    "                layers.append(np.maximum(0, layers[-1]))\n",
    "            print(layers[-1].shape)\n",
    "        \n",
    "        return layers[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNeuralNet = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 718)\n",
      "(1, 512)\n",
      "(1, 512)\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0864664 , 0.16715338, 0.10173483, 0.10064541, 0.09063523,\n",
       "        0.07917663, 0.05446409, 0.13409147, 0.0851065 , 0.10052606]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = myNeuralNet.forward(np.random.rand(1, 718))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = np.array([1,2,3])\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 += 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.90488497e+13, 7.89629602e+13, 2.14643580e+14])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = np.exp(test1)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322655389633844.2"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = np.sum(test1)\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09003057, 0.24472847, 0.66524096])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = test1 / sum\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.79876162, 0.90084167, 0.4401192 , ..., 0.98484349, 0.78392602,\n",
       "         0.1411576 ],\n",
       "        [0.14452771, 0.3616537 , 0.55987813, ..., 0.53699564, 0.80833471,\n",
       "         0.90234479],\n",
       "        [0.59664433, 0.83712402, 0.07534923, ..., 0.5817613 , 0.90192853,\n",
       "         0.83691691],\n",
       "        ...,\n",
       "        [0.69490799, 0.31286115, 0.47560318, ..., 0.12409177, 0.67196322,\n",
       "         0.69876002],\n",
       "        [0.43198313, 0.30954852, 0.98144773, ..., 0.33922956, 0.78060173,\n",
       "         0.44827809],\n",
       "        [0.55082264, 0.63352575, 0.66652466, ..., 0.72324706, 0.94841395,\n",
       "         0.6914613 ]]),\n",
       " array([[0.54007279, 0.14734038, 0.61046204, ..., 0.04570406, 0.04643376,\n",
       "         0.63147651],\n",
       "        [0.65448902, 0.84974573, 0.90313734, ..., 0.48914766, 0.46126397,\n",
       "         0.50053977],\n",
       "        [0.28161597, 0.77680599, 0.76626299, ..., 0.29413661, 0.61503144,\n",
       "         0.62840997],\n",
       "        ...,\n",
       "        [0.28088512, 0.76910848, 0.20913243, ..., 0.98918204, 0.87833887,\n",
       "         0.55507491],\n",
       "        [0.83977051, 0.48941252, 0.97323008, ..., 0.13720031, 0.56795736,\n",
       "         0.016561  ],\n",
       "        [0.29767018, 0.83088749, 0.06621612, ..., 0.68267621, 0.64102248,\n",
       "         0.48682738]]),\n",
       " array([[0.5911781 , 0.35040952, 0.71213303, ..., 0.09158234, 0.24989118,\n",
       "         0.43430904],\n",
       "        [0.72582578, 0.93180619, 0.69744607, ..., 0.89672871, 0.41805683,\n",
       "         0.22177538],\n",
       "        [0.30545954, 0.34040146, 0.13279053, ..., 0.63454751, 0.70078904,\n",
       "         0.95471358],\n",
       "        ...,\n",
       "        [0.93420996, 0.00434329, 0.90180401, ..., 0.0276755 , 0.66670133,\n",
       "         0.20829742],\n",
       "        [0.62770985, 0.87732802, 0.21335482, ..., 0.41987313, 0.32977093,\n",
       "         0.83976059],\n",
       "        [0.35708339, 0.35889034, 0.39939742, ..., 0.87249226, 0.10846544,\n",
       "         0.48681089]])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralNetwork().weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(batchNumber[32], inputs[718]) * (weights[718], weights[512]) = (32, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implement GitHub Repo\n",
    "\n",
    "Forward pass - Train \n",
    "    - Neurons + Acitvation function + Softwax (get probablities) + loss\n",
    "    - Test Forward Pass with Other Model Gradients\n",
    "\n",
    "Implement backpropagation\n",
    "    - Explain how to do and everything\n",
    "    - Start training with basic 80-20\n",
    "\n",
    "Introduce regularization\n",
    "Batch Normalization\n",
    "\n",
    "Optimizer\n",
    "\n",
    "Visualize gradients\n",
    "\n",
    "Visualize MNIST with UMAP or T-SNE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
